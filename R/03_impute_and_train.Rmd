---
title: "03: Impute data and train model"
output: html_notebook
---

## Setup
```{r}
library(magrittr)
library(futile.logger)
library(caret)
library(mice)
library(foreach)
library(doParallel)

source("imputation_definitions.R")
source("functionals.R")
```

```{r}
training_data <- read.csv("../contracted_training_data.csv", row.names=1, as.is = TRUE) 
outcome <- read.csv("../outcomes.csv", as.is = TRUE)

outcome <- factor(outcome[,2], levels = c("1", "0"), labels = c("positive", "negative"))
```

## Removal of problematic features

### Near-zero variance
```{r}
nearzerovariance <- caret::nearZeroVar(training_data, saveMetrics = TRUE)
print(nearzerovariance[nearzerovariance$nzv, ])

if (any(nearzerovariance$nzv)) {
  training_data <- training_data[, !nearzerovariance$nzv]
}
```

### Highly correlated features
```{r}
correlations <- cor(training_data, use = "pairwise.complete.obs")
correlations[is.na(correlations)] <- 0.0

highly_correlated_variables <- caret::findCorrelation(correlations, verbose = TRUE, names = TRUE)
print(highly_correlated_variables)

if(highly_correlated_variables %>% length > 0) {
  training_data <- training_data[, !colnames(training_data) %in% highly_correlated_variables]
}
```

## Imputation
```{r}
lapply(imputation_hyperparameter_grids, nrow)
```

```{r}
run_imputation_method <- function(data, method, hyperparams, times, iterations) {

  print(paste0("Starting with ", paste0(hyperparams, collapse = ", "), ", imputing ", times, " times"))

  imputation_object <- mice::mice(data = data, method = method,  m = times, maxit = iterations, printFlag = FALSE, ... = hyperparams)

  print("done with imputation")

  completed_datasets <- mice::complete(imputation_object, action = "all")

  print("done with forming datasets")

  return(list(completed_datasets = completed_datasets, imputation_object = imputation_object))
}

times <- 2
iters <- 5

timings <- list()

imputation_result_per_imp_method <- foreach(method = enumerate(imputation_hyperparameter_grids)) %do% {

  hyperparams <- method$value

  timings[[method$name]] <- list()

  imputation_result_per_hp_set <- foreach(hp_set = 1:nrow(hyperparams)) %do% {
    timings[[method$name]][[hp_set]] <- system.time(
      imputation_result <- tryCatch(
        run_imputation_method(data = training_data, method = method$name, iterations = iters, hyperparams = unlist(hyperparams[hp_set,]), times = times), 
        error = function(e) {
          print(e)
          return(NULL)
        }
      )
    )
    return(imputation_result)
  }
  names(imputation_result_per_hp_set) <- 1:nrow(hyperparams)
  timings[[method$name]] = do.call(rbind, timings[[method$name]])

  return(imputation_result_per_hp_set)
}
names(imputation_result_per_imp_method) <- names(imputation_hyperparameter_grids)
```

## Training
```{r}
hyperparameter_grid <- data.frame(mtry = 1:5 * 8 - 1)

training_settings <- trainControl(classProbs = TRUE,
                                  verboseIter = FALSE,
                                  method = "oob",
                                  returnResamp = "final")

train_on_imp_rep <- function(imputed_dataset_per_imp_rep) {
      train_args <- list(x = imputed_dataset_per_imp_rep,
                         y = outcome,
                         method = "rf",
                         preProcess = c("center", "scale"),
                         trControl = training_settings,
                         tuneGrid = hyperparameter_grid)

      rf_model <- do.call(caret::train, train_args)
      return(rf_model)
}

models <- recursive_apply(x = imputation_result_per_imp_method, fun = train_on_imp_rep, x_class = "data.frame")
```

```{r}
library(ModelMetrics)

extract_oob_performance <- function(model) {
  model$finalModel$err.rate[, "OOB"] %>% tail(1)
}

oobs <- recursive_apply(models, extract_oob_performance, "train")
best_rf_per_method_per_hp_per_completed_means <- leaf_apply(oobs, . %>% unlist %>% mean, docall = FALSE)
best_rf_per_method_per_hp_per_completed_means <- leaf_apply(best_rf_per_method_per_hp_per_completed_means, . %>% unlist, docall = FALSE)
best_hp_sets_per_method <- leaf_apply(best_rf_per_method_per_hp_per_completed_means, which.min, docall = FALSE)

best_models_per_method <- lapply(enumerate(best_hp_sets_per_method), function(x) with(x, models[[name]][[value]]))
best_imputers_per_method <- lapply(enumerate(best_hp_sets_per_method), function(x) with(x, imputation_result_per_imp_method[[name]][[value]]))
best_hp_configs_per_method <- lapply(enumerate(best_hp_sets_per_method), function(x) with(x, imputation_hyperparameter_grids[[name]][value, ]))

imputation_convergence_plots <- lapply(best_imputers_per_method, function(x) recursive_apply(x, plot, "mids"))

classifier_oob_plots <- recursive_apply(best_models_per_method, plot, x_class = "train")
```

## Saving model
```{r}
if (!dir.exists("../output")) {
  dir_creation_success <- dir.create("../output", showWarnings = TRUE)
  if (!dir_creation_success) {
    stop("Failed to create directory for saving output.")
  }
}

saveRDS(best_models_per_method, file = "../output/classifier_models.rds")
saveRDS(best_imputers_per_method, file = "../output/imputers_models.rds")
saveRDS(best_hp_configs_per_method, file = "../output/hp_configs_models.rds")
```
