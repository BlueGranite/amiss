---
title: "Prediction on test set"
output: html_notebook
---

## Read data
```{r}
library(magrittr)
library(mice)
library(caret)

source("recursive_application.R")
source("imputation.R")

test_data <- read.csv("../contracted_test_data.csv", row.names = 1, as.is = TRUE)
outcome <- read.csv("../test_outcomes.csv", as.is = TRUE)

# Keep exactly those features that were kept in training data
final_features <- readRDS("../output/final_features.rds")
test_data <- test_data[, final_features]

# Recode outcomes as 1 -> "positive", 0 -> "negative"
outcome <- factor(outcome[,2], levels = c("1", "0"), labels = c("positive", "negative"))
head(outcome)
```

## Multiply impute the test set using the best hyperparameter configurations from the training set
```{r}
rf_imputers <- readRDS("../output/rf_imputers_models.rds")
rf_hyperparams <- readRDS("../output/rf_hp_configs_models.rds")
lr_imputers <- readRDS("../output/lr_imputers_models.rds")
lr_hyperparams <- readRDS("../output/lr_hp_configs_models.rds")

times <- 5
iters <- 1

# Create a tree of functions with hyperparameter configurations fixed by currying the
# mice function; i.e. create new functions with all arguments besides `method` fixed
rf_imputation_functions <- lapply(rf_hyperparams, FUN = function(hps) {
  function(method) run_mice(test_data, method, hps, times, iters)
})
# Run each function in the tree using the method designated by the subtree
rf_imputations <- lapply(names(rf_imputation_functions), 
                         function(method) {
                           recursive_apply(rf_imputation_functions[[method]], 
                                           fun = function(x) x(method), 
                                           "function")
                         })
names(rf_imputations) <- names(rf_imputation_functions)

lr_imputation_functions <- lapply(lr_hyperparams, FUN = function(hps) {
  function(method) run_mice(test_data, method, hps, times, iters)
})
lr_imputations <- lapply(names(lr_imputation_functions), 
                         function(method) {
                           recursive_apply(lr_imputation_functions[[method]], 
                                           fun = function(x) x(method), 
                                           "function")
                         })
names(lr_imputations) <- names(lr_imputation_functions)

# In case some variables were not otherwise imputable on the test set for whatever reason, run median imputation on them.
rf_completions <- recursive_apply(rf_imputations, function(df) lapply(df, median_imp) %>% data.frame, "data.frame")
lr_completions <- recursive_apply(lr_imputations, function(df) lapply(df, median_imp) %>% data.frame, "data.frame")
```

## Predict on test set completions using best classifier models
```{r}
rf_models <- readRDS("../output/rf_classifier_models.rds")
lr_models <- readRDS("../output/lr_classifier_models.rds")

prediction <- function(models, completions) {
  
  predictions <- lapply(names(models), function(method) {
    
    pred_per_model <- lapply(models[[method]], function(model) {
      
      pred_per_completion <- recursive_apply(completions, function(completed_dataset) {
        predict(model, completed_dataset, type = "prob")[,"positive", drop = TRUE]
      }, "data.frame")
      
      names(pred_per_completion) <- paste0("imp_", 1:length(pred_per_completion))
      pred_per_completion
      
    })
    
    names(pred_per_model) <- paste0("model_", 1:length(pred_per_model))
    pred_per_model
    
  })
  names(predictions) <- names(models)
  return(predictions)
}

rf_predictions <- prediction(rf_models, rf_completions)
lr_predictions <- prediction(lr_models, lr_completions)
```

## Compute performance statistics on the test set
```{r}
rf_confusion_matrices <- recursive_apply(rf_predictions, function(pred) {
  pred <- factor(c("positive", "negative")[2 - (pred > 0.5)], c("positive", "negative"))
  caret::confusionMatrix(pred, outcome)
}, x_class = "numeric")

lr_confusion_matrices <- recursive_apply(lr_predictions, function(pred) {
  pred <- factor(c("positive", "negative")[2 - (pred > 0.5)], c("positive", "negative"))
  caret::confusionMatrix(pred, outcome)
}, x_class = "numeric")

rf_mccs <- recursive_apply(rf_predictions, function(pred) ModelMetrics::mcc(as.integer(outcome == "positive"), pred, 0.5), x_class = "numeric")
rf_aucs <- recursive_apply(rf_predictions, function(pred) ModelMetrics::auc(as.integer(outcome == "positive"), pred), x_class = "numeric")

rf_mean_mccs <- leaf_apply(rf_mccs, . %>% unlist %>% mean, FALSE)
rf_mean_aucs <- leaf_apply(rf_aucs, . %>% unlist %>% mean, FALSE)

rf_sd_mccs <- leaf_apply(rf_mccs, . %>% unlist %>% sd, FALSE)
rf_sd_aucs <- leaf_apply(rf_aucs, . %>% unlist %>% sd, FALSE)

rf_mean_mean_mccs <- leaf_apply(rf_mean_mccs, . %>% unlist %>% mean, FALSE)
rf_mean_mean_aucs <- leaf_apply(rf_mean_aucs, . %>% unlist %>% mean, FALSE)

rf_sd_mean_mccs <- leaf_apply(rf_mean_mccs, . %>% unlist %>% sd, FALSE)
rf_sd_mean_aucs <- leaf_apply(rf_mean_aucs, . %>% unlist %>% sd, FALSE)

lr_mccs <- recursive_apply(lr_predictions, function(pred) ModelMetrics::mcc(as.integer(outcome == "positive"), pred, 0.5), x_class = "numeric")
lr_aucs <- recursive_apply(lr_predictions, function(pred) ModelMetrics::auc(as.integer(outcome == "positive"), pred), x_class = "numeric")

lr_mean_mccs <- leaf_apply(lr_mccs, . %>% unlist %>% mean, FALSE)
lr_mean_aucs <- leaf_apply(lr_aucs, . %>% unlist %>% mean, FALSE)

lr_sd_mccs <- leaf_apply(lr_mccs, . %>% unlist %>% sd, FALSE)
lr_sd_aucs <- leaf_apply(lr_aucs, . %>% unlist %>% sd, FALSE)

lr_mean_mean_mccs <- leaf_apply(lr_mean_mccs, . %>% unlist %>% mean, FALSE)
lr_mean_mean_aucs <- leaf_apply(lr_mean_aucs, . %>% unlist %>% mean, FALSE)

lr_sd_mean_mccs <- leaf_apply(lr_mean_mccs, . %>% unlist %>% sd, FALSE)
lr_sd_mean_aucs <- leaf_apply(lr_mean_aucs, . %>% unlist %>% sd, FALSE)
```