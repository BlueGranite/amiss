---
title: "Prediction on test set"
output: html_notebook
---

## Read data
```{r}
library(magrittr)
library(mice)
library(caret)

source("recursive_application.R")
source("imputation.R")

test_data <- read.csv("../contracted_test_data.csv", row.names = 1, as.is = TRUE)
outcome <- read.csv("../test_outcomes.csv", as.is = TRUE)

# Keep exactly those features that were kept in training data
final_features <- readRDS("../output/final_features.rds")
test_data <- test_data[, final_features]

# Recode outcomes as 1 -> "positive", 0 -> "negative"
outcome <- factor(outcome[,2], levels = c("1", "0"), labels = c("positive", "negative"))
head(outcome)
```

## Multiply impute the test set using the best hyperparameter configurations from the training set
```{r}
rf_hyperparams <- readRDS("../output/rf_hp_configs.rds")
lr_hyperparams <- readRDS("../output/lr_hp_configs.rds")

times <- 5
iters <- 1

impute_w_hps <- function(data, hp_tree){

  # Create a tree of functions with hyperparameter configurations fixed by currying the
  # mice function; i.e. create new functions with all arguments besides `method` fixed
  imputation_functions <- lapply(hp_tree, FUN = function(hps) {
    function(method) run_mice(data, method, hps, times, iters)
  })

  # Run each function in the tree using the method designated by the subtree
  imputations <- lapply(names(imputation_functions),
                        function(method) {
                          recursive_apply(imputation_functions[[method]],
                                          fun = function(x) x(method),
                                          "function")
                        })
  names(imputations) <- names(imputation_functions)

  # In case some variables were not otherwise imputable on the test set for whatever reason, run median imputation on them.
  completions <- recursive_apply(imputations, function(df) lapply(df, median_imp) %>% data.frame, "data.frame")

  return(completions)
}
rf_completions <- impute_w_hps(test_data, rf_hyperparams)
lr_completions <- impute_w_hps(test_data, lr_hyperparams)
```

## Predict on test set completions using best classifier models
```{r}
rf_models <- readRDS("../output/rf_classifiers.rds")
lr_models <- readRDS("../output/lr_classifiers.rds")

prediction <- function(models, completions) {

  predictions <- lapply(names(models), function(method) {

    pred_per_model <- lapply(models[[method]], function(model) {

      pred_per_completion <- recursive_apply(completions, function(completed_dataset) {
        predict(model, completed_dataset, type = "prob")[,"positive", drop = TRUE]
      }, "data.frame")

      names(pred_per_completion) <- paste0("imp_", 1:length(pred_per_completion))
      pred_per_completion

    })

    names(pred_per_model) <- paste0("model_", 1:length(pred_per_model))
    pred_per_model

  })
  names(predictions) <- names(models)
  return(predictions)
}

rf_predictions <- prediction(rf_models, rf_completions)
lr_predictions <- prediction(lr_models, lr_completions)
```

## Compute performance statistics on the test set
```{r}
performance_stats <- function(predictions) {

  confusion_matrices <- recursive_apply(predictions, function(pred) {
    pred <- factor(c("positive", "negative")[2 - (pred > 0.5)], c("positive", "negative"))
    caret::confusionMatrix(pred, outcome)
  }, x_class = "numeric")

  mccs <- recursive_apply(predictions, function(pred) ModelMetrics::mcc(as.integer(outcome == "positive"), pred, 0.5), x_class = "numeric")
  aucs <- recursive_apply(predictions, function(pred) ModelMetrics::auc(as.integer(outcome == "positive"), pred), x_class = "numeric")

  mean_mccs <- leaf_apply(mccs, . %>% unlist %>% mean, FALSE)
  mean_aucs <- leaf_apply(aucs, . %>% unlist %>% mean, FALSE)

  sd_mccs <- leaf_apply(mccs, . %>% unlist %>% sd, FALSE)
  sd_aucs <- leaf_apply(aucs, . %>% unlist %>% sd, FALSE)

  mean_mean_mccs <- leaf_apply(mean_mccs, . %>% unlist %>% mean, FALSE)
  mean_mean_aucs <- leaf_apply(mean_aucs, . %>% unlist %>% mean, FALSE)

  sd_mean_mccs <- leaf_apply(mean_mccs, . %>% unlist %>% sd, FALSE)
  sd_mean_aucs <- leaf_apply(mean_aucs, . %>% unlist %>% sd, FALSE)

  perfs <- list(mccs = mccs,
                mean_mccs = mean_mccs,
                sd_mccs = sd_mccs,
                mean_mean_mccs =  mean_mean_mccs,
                sd_mean_mccs = sd_mean_mccs,

                aucs = aucs,
                mean_aucs = mean_aucs,
                sd_aucs = sd_aucs,
                mean_mean_aucs = mean_mean_aucs,
                sd_mean_aucs = sd_mean_aucs)

  return(perfs)

}
rf_perf <- performance_stats(rf_predictions)
lr_perf <- performance_stats(lr_predictions)
```